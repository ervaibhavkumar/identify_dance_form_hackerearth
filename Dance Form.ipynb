{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nimport cv2\nimport math\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom keras.utils.np_utils import to_categorical\nfrom skimage.transform import rotate","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Get files from a path"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_files(path):\n    files = list()\n    \n    # /kaggle/input/dataset/train\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            files.append(os.path.join(dirname, filename))\n    \n    return files","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_files_path = get_files('/kaggle/input/dance-form-vaibhav/dataset/train/')\n\ntrain_csv = pd.read_csv('/kaggle/input/dance-form-vaibhav/dataset/train.csv')\n\nprint(\"Train files : {0}\".format(len(train_files_path)))","execution_count":3,"outputs":[{"output_type":"stream","text":"Train files : 364\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dict = dict(zip(train_csv.Image, train_csv.target))\nprint(train_dict['96.jpg'])","execution_count":4,"outputs":[{"output_type":"stream","text":"manipuri\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Split into training and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"split = int(len(train_files_path) * 0.83)\nrandom.shuffle(train_files_path)\ntrain_files = train_files_path[:split]\nval_files = train_files_path[split:]\n\nprint(\"Training files {0}\".format(len(train_files)))\nprint(\"Validation files {0}\".format(len(val_files)))","execution_count":5,"outputs":[{"output_type":"stream","text":"Training files 302\nValidation files 62\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Converting dance forms into numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_labels = list(set(train_dict.values()))\nunique_labels_mapping = dict()\nfor index in range(len(unique_labels)):\n    unique_labels_mapping[unique_labels[index]] = index\n\ntotal_classes = len(unique_labels)\nprint(\"Number of classes : {0}\".format(total_classes))","execution_count":6,"outputs":[{"output_type":"stream","text":"Number of classes : 8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_one_hot_encoded_mask(value, num_labels):\n    return to_categorical(value, num_classes = num_labels)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting up hyper-parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 256, 256\nbatch_size = 16\nepochs = 10\nlearning_rate = 1e-3","execution_count":58,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Augmentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rotate_image(image, angle_list):\n    rotated_images = list()\n    for angle in angle_list:\n        rotated_images.append(rotate(image,angle))\n    \n    return rotated_images","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaleDown_image(image, fx=0.6, fy=0.6):\n    return cv2.resize(image, None, fx= 0.6, fy= 0.6, interpolation= cv2.INTER_LINEAR)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaleUp_image(image, fx = 2, fy = 2):\n    return cv2.resize(image, None, fx = fx, fy = fy, interpolation= cv2.INTER_LINEAR)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def horizontal_flip(img):\n    return img[: , ::-1]","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating DataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator:\n    def __init__(self, train_files, valid_files, labels_dict, batch_size = 16, val_augment = True):\n        self.train_files = train_files\n        self.valid_files = valid_files\n        self.labels_dict = labels_dict\n        self.batch_size = batch_size\n        self.val_augment = val_augment\n        \n    def train_generator(self):\n        num_images = len(self.train_files)\n        while True:\n            x_batch = list()\n            y_batch = list()\n            index_list = list(range(0,num_images))\n            index_list = shuffle(index_list)\n            for idxs in range(0, num_images, self.batch_size):\n                x_batch = list()\n                y_batch = list()\n                for idx in index_list[idxs:min(idxs+self.batch_size, num_images)]:\n                    \n                    img = cv2.imread(self.train_files[idx])\n                    img = cv2.resize(img, (img_width, img_height))\n                    x_batch.append(img)\n                    \n                    image_name = self.train_files[idx].split(\"/\")\n                    label = unique_labels_mapping[train_dict[str(image_name[-1])]]\n                    label = get_one_hot_encoded_mask(label, total_classes)\n                    y_batch.append(label)\n                    \n                    rotated_images = rotate_image(img, [45, 60, -45, -60])\n                    for rotated_image in rotated_images:\n                        x_batch.append(rotated_image)\n                        y_batch.append(label)\n                                        \n                    x_batch.append(horizontal_flip(img))\n                    y_batch.append(label)\n                \n                yield (np.asarray(x_batch), np.asarray(y_batch))\n    \n    def valid_generator(self):\n        num_images = len(self.valid_files)\n        while True:\n            x_batch = list()\n            y_batch = list()\n            index_list = list(range(0,num_images))\n            index_list = shuffle(index_list)\n            for idxs in range(0, num_images, self.batch_size):\n                x_batch = list()\n                y_batch = list()\n                for idx in index_list[idxs:min(idxs+self.batch_size, num_images)]:\n                    \n                    img = cv2.imread(self.valid_files[idx])\n                    img = cv2.resize(img, (img_width, img_height))\n                    x_batch.append(img)\n                    \n                    image_name = self.valid_files[idx].split(\"/\")\n                    label = unique_labels_mapping[train_dict[str(image_name[-1])]]\n                    label = get_one_hot_encoded_mask(label, total_classes)\n                    y_batch.append(label)\n                    \n                    if self.val_augment:\n                        rotated_images = rotate_image(img, [45, 60, -45, -60])\n                        for rotated_image in rotated_images:\n                            x_batch.append(rotated_image)\n                            y_batch.append(label)\n\n                        x_batch.append(horizontal_flip(img))\n                        y_batch.append(label)\n                        \n                yield (np.asarray(x_batch), np.asarray(y_batch))","execution_count":55,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Experiments"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import vgg19\nfrom keras.layers import Dense, GlobalAveragePooling2D, Flatten\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Model","execution_count":62,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VGG16 Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = vgg19.VGG19(include_top=False, input_shape=(img_width, img_height, 3), \\\n                    weights='/kaggle/input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\nmodel.summary()","execution_count":15,"outputs":[{"output_type":"stream","text":"Model: \"vgg19\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n=================================================================\nTotal params: 20,024,384\nTrainable params: 20,024,384\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch_steps = int(math.ceil(len(train_files) / batch_size))\nprint(epoch_steps)\nval_steps = int(math.ceil(len(val_files) / batch_size))\nprint(val_steps)","execution_count":16,"outputs":[{"output_type":"stream","text":"19\n4\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = model.output\nx = Flatten()(x)\nx = Dense(512,activation='relu')(x)\nx = Dense(256,activation='relu')(x)\nfinal_layer = Dense(total_classes,activation='softmax')(x)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Model(inputs=model.input,outputs=final_layer)\nmodel.summary()","execution_count":18,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 32768)             0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               16777728  \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_2 (Dense)              (None, 8)                 2056      \n=================================================================\nTotal params: 36,935,496\nTrainable params: 36,935,496\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=SGD(learning_rate=learning_rate , momentum = 0.9), \n              loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = DataGenerator(train_files, val_files, train_dict, batch_size)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(generator=datagen.train_generator() , steps_per_epoch=epoch_steps, \n                             epochs=10, validation_steps = val_steps, \n                             validation_data=datagen.valid_generator(), verbose=2)","execution_count":61,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n19/19 - 22s - loss: 2.0766 - accuracy: 0.1391 - val_loss: 2.0938 - val_accuracy: 0.0484\nEpoch 2/10\n19/19 - 23s - loss: 2.0761 - accuracy: 0.1391 - val_loss: 2.0915 - val_accuracy: 0.0645\nEpoch 3/10\n19/19 - 22s - loss: 2.0756 - accuracy: 0.1391 - val_loss: 2.0932 - val_accuracy: 0.0484\nEpoch 4/10\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-886a3e5cee43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(generator=datagen.train_generator() , steps_per_epoch=epoch_steps, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              validation_data=datagen.valid_generator(), verbose=2)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}