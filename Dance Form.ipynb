{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom keras.utils.np_utils import to_categorical\nfrom skimage.transform import rotate","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Get files from a path","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_files(path):\n    files = list()\n    \n    # /kaggle/input/dataset/train\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            files.append(os.path.join(dirname, filename))\n    \n    return files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_files_path = get_files('/kaggle/input/dataset/train')\n\ntrain_csv = pd.read_csv('/kaggle/input/dataset/train.csv')\n\nprint(\"Train files : {0}\".format(len(train_files_path)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dict = dict(zip(train_csv.Image, train_csv.target))\nprint(train_dict['96.jpg'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split into training and validation set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"split = int(len(train_files_path) * 0.83)\nrandom.shuffle(train_files_path)\ntrain_files = train_files_path[:split]\nval_files = train_files_path[split:]\n\nprint(\"Training files {0}\".format(len(train_files)))\nprint(\"Validation files {0}\".format(len(val_files)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting dance forms into numbers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_labels = list(set(train_dict.values()))\nunique_labels_mapping = dict()\nfor index in range(len(unique_labels)):\n    unique_labels_mapping[unique_labels[index]] = index\n\ntotal_classes = len(unique_labels)\nprint(\"Number of classes : {0}\".format(total_classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_one_hot_encoded_mask(value, num_labels):\n    return to_categorical(value, num_classes = num_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting up hyper-parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 256, 256\nbatch_size = 16\nepochs = 10\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Augmentations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def rotate_image(image, angle_list):\n    rotated_images = list()\n    for angle in angle_list:\n        rotatef_images.append(rotate(image,angle))\n    \n    return rotated_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaleDown_image(image, fx=0.6, fy=0.6):\n    return cv2.resize(img, None, fx= 0.6, fy= 0.6, interpolation= cv2.INTER_LINEAR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaleUp_image(image, fx = 2, fy = 2):\n    return cv2.resize(img, None, fx = fx, fy = fy, interpolation= cv2.INTER_LINEAR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def horizontal_flip(img):\n    return img[: , ::-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating DataGenerator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator:\n    def __init__(self, train_files, valid_files, labels_dict, batch_size = 16):\n        self.train_files = train_files\n        self.valid_files = valid_files\n        self.labels_dict = labels_dict\n        self.batch_size = batch_size\n        \n    def train_generator(self):\n        num_images = len(self.train_files)\n        while True:\n            x_batch = list()\n            y_batch = list()\n            index_list = list(range(0,num_images))\n            index_list = shuffle(index_list)\n            for idxs in range(0, num_images, self.batch_size):\n                for idx in index_list[idxs:min(idxs+self.batch_size, num_images)]:\n                    \n                    img = cv2.imread(self.train_files[idx])\n                    img = cv2.resize(img, (img_width, img_height))\n                    x_batch.append(img)\n                    \n                    image_name = self.train_files[idx].split(\"/\")\n                    label = unique_labels_mapping[train_dict[str(image_name)]]\n                    y_batch.append(label)\n                    \n                    rotated_images = rotate_image(img, [45, 60, -45, -60])\n                    for rotated_image in rotated_images:\n                        x_batch.append(rotate_image)\n                        y_batch.append(label)\n                    \n                    x_batch.append(scaleDown_image(img))\n                    y_batch.append(label)\n                    \n                    x_batch.append(scaleUp_image(img))\n                    y_batch.append(label)\n                    \n                    x_batch.append(horizontal_flip(img))\n                    y_batch.append(label)\n                \n                yield (np.array(x_batch), np.array(y_batch))\n    \n    def valid_generator(self):\n        num_images = len(self.valid_files)\n        while True:\n            x_batch = list()\n            y_batch = list()\n            index_list = list(range(0,num_images))\n            index_list = shuffle(index_list)\n            for idxs in range(0, num_images, self.batch_size):\n                for idx in index_list[idxs:min(idxs+self.batch_size, num_images)]:\n                    \n                    img = cv2.imread(self.valid_files[idx])\n                    img = cv2.resize(img, (img_width, img_height))\n                    x_batch.append(img)\n                    \n                    image_name = self.valid_files[idx].split(\"/\")\n                    label = unique_labels_mapping[train_dict[str(image_name)]]\n                    y_batch.append(label)\n                    \n                    rotated_images = rotate_image(img, [45, 60, -45, -60])\n                    for rotated_image in rotated_images:\n                        x_batch.append(rotate_image)\n                        y_batch.append(label)\n                    \n                    x_batch.append(scaleDown_image(img))\n                    y_batch.append(label)\n                    \n                    x_batch.append(scaleUp_image(img))\n                    y_batch.append(label)\n                    \n                    x_batch.append(horizontal_flip(img))\n                    y_batch.append(label)\n                \n                yield (np.array(x_batch), np.array(y_batch))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}